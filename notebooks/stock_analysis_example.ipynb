{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec12201c",
   "metadata": {},
   "source": [
    "# Stock Price Prediction with LSTM - Example Usage\n",
    "\n",
    "This notebook demonstrates how to use the stock prediction package to analyze stock prices and make future predictions.\n",
    "\n",
    "## Features Demonstrated\n",
    "- Data loading and preprocessing\n",
    "- LSTM model training\n",
    "- Price prediction\n",
    "- Risk classification\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f87f69",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e61a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from src.data_processor import StockDataProcessor\n",
    "from src.model import LSTMModel\n",
    "from src.predictor import StockPredictor, RiskClassifier\n",
    "from src.visualizer import StockVisualizer\n",
    "from src.utils import set_random_seeds, create_output_directories\n",
    "import config\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "set_random_seeds(42)\n",
    "\n",
    "# Create output directories\n",
    "create_output_directories()\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e0f6d1",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45448c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = StockDataProcessor(window_size=3)\n",
    "\n",
    "# Load sample data (replace with your data path)\n",
    "data_path = '../data/raw/sample_stock_data.csv'  # Update this path\n",
    "\n",
    "# Create sample data if it doesn't exist\n",
    "if not os.path.exists(data_path):\n",
    "    print(\"Creating sample data...\")\n",
    "    \n",
    "    # Generate sample stock data\n",
    "    dates = pd.date_range('2010-01-01', '2021-12-31', freq='D')\n",
    "    np.random.seed(42)\n",
    "    prices = 100 + np.cumsum(np.random.randn(len(dates)) * 0.5)\n",
    "    \n",
    "    sample_data = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Close': prices,\n",
    "        'Index': 'SAMPLE'\n",
    "    })\n",
    "    \n",
    "    os.makedirs('../data/raw', exist_ok=True)\n",
    "    sample_data.to_csv(data_path, index=False)\n",
    "    print(f\"Sample data created at {data_path}\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "df, scaler = processor.load_and_preprocess(data_path, 'SAMPLE')\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9eb86",
   "metadata": {},
   "source": [
    "## 3. Visualize Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = StockVisualizer()\n",
    "\n",
    "# Plot historical prices (normalized)\n",
    "visualizer.plot_price_history(df, \"Historical Stock Prices (Normalized)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec3604",
   "metadata": {},
   "source": [
    "## 4. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7990b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windowed dataset\n",
    "dates, X, y = processor.df_to_windowed_df_simple(df)\n",
    "\n",
    "print(f\"Windowed data shapes:\")\n",
    "print(f\"Dates: {dates.shape}\")\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Targets (y): {y.shape}\")\n",
    "\n",
    "# Split data into train/validation/test sets\n",
    "data_splits = processor.split_data(dates, X, y)\n",
    "\n",
    "print(f\"\\nData splits:\")\n",
    "print(f\"Training: {data_splits['X_train'].shape[0]} samples\")\n",
    "print(f\"Validation: {data_splits['X_val'].shape[0]} samples\")\n",
    "print(f\"Test: {data_splits['X_test'].shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566374e0",
   "metadata": {},
   "source": [
    "## 5. Visualize Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e557a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data splits\n",
    "visualizer.plot_data_splits(\n",
    "    data_splits['dates_train'], data_splits['y_train'],\n",
    "    data_splits['dates_val'], data_splits['y_val'],\n",
    "    data_splits['dates_test'], data_splits['y_test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb2379",
   "metadata": {},
   "source": [
    "## 6. Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16cca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model = LSTMModel(window_size=3, lstm_units=64, dense_units=32)\n",
    "\n",
    "print(\"Training LSTM model...\")\n",
    "trained_model = model.train_simple(\n",
    "    data_splits['X_train'], data_splits['y_train'],\n",
    "    data_splits['X_val'], data_splits['y_val'],\n",
    "    epochs=50  # Reduced for faster execution in notebook\n",
    ")\n",
    "\n",
    "print(\"Model training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d11e71",
   "metadata": {},
   "source": [
    "## 7. Make Predictions and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f227c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on all datasets\n",
    "train_predictions = trained_model.predict(data_splits['X_train'], verbose=0).flatten()\n",
    "val_predictions = trained_model.predict(data_splits['X_val'], verbose=0).flatten()\n",
    "test_predictions = trained_model.predict(data_splits['X_test'], verbose=0).flatten()\n",
    "\n",
    "# Evaluate model performance\n",
    "from src.utils import calculate_metrics\n",
    "\n",
    "train_metrics = calculate_metrics(data_splits['y_train'], train_predictions)\n",
    "val_metrics = calculate_metrics(data_splits['y_val'], val_predictions)\n",
    "test_metrics = calculate_metrics(data_splits['y_test'], test_predictions)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Train MAE: {train_metrics['MAE']:.6f}\")\n",
    "print(f\"Validation MAE: {val_metrics['MAE']:.6f}\")\n",
    "print(f\"Test MAE: {test_metrics['MAE']:.6f}\")\n",
    "\n",
    "print(f\"\\nTest RMSE: {test_metrics['RMSE']:.6f}\")\n",
    "print(f\"Test MAPE: {test_metrics['MAPE']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1323a989",
   "metadata": {},
   "source": [
    "## 8. Visualize Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae1502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "visualizer.plot_training_results(\n",
    "    data_splits['dates_train'], data_splits['y_train'], train_predictions,\n",
    "    data_splits['dates_val'], data_splits['y_val'], val_predictions,\n",
    "    data_splits['dates_test'], data_splits['y_test'], test_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b962bb",
   "metadata": {},
   "source": [
    "## 9. Risk Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize risk classifier\n",
    "classifier = RiskClassifier()\n",
    "\n",
    "# Denormalize test predictions for classification\n",
    "test_predictions_denorm = scaler.inverse_transform(\n",
    "    test_predictions.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "# Generate daily and monthly classifications\n",
    "daily_classification = classifier.classify_daily(\n",
    "    data_splits['dates_test'], test_predictions_denorm, \"SAMPLE\"\n",
    ")\n",
    "\n",
    "monthly_classification = classifier.classify_monthly(\n",
    "    data_splits['dates_test'], test_predictions_denorm, \"SAMPLE\"\n",
    ")\n",
    "\n",
    "print(f\"Daily classifications: {len(daily_classification)} records\")\n",
    "print(f\"Monthly classifications: {len(monthly_classification)} records\")\n",
    "\n",
    "# Show classification distribution\n",
    "print(\"\\nDaily Classification Distribution:\")\n",
    "print(daily_classification['Classification'].value_counts())\n",
    "\n",
    "print(\"\\nMonthly Classification Distribution:\")\n",
    "print(monthly_classification['Classification'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e991f1",
   "metadata": {},
   "source": [
    "## 10. Visualize Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d376ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily classifications\n",
    "visualizer.plot_daily_classifications(daily_classification)\n",
    "\n",
    "# Plot monthly classifications\n",
    "visualizer.plot_monthly_classifications(monthly_classification)\n",
    "\n",
    "# Plot classification distribution\n",
    "visualizer.plot_classification_distribution(\n",
    "    daily_classification['Classification'],\n",
    "    \"Daily Risk Classification Distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0c2fe",
   "metadata": {},
   "source": [
    "## 11. Future Price Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295efd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize predictor\n",
    "predictor = StockPredictor(trained_model, scaler)\n",
    "\n",
    "# Predict future prices (next 60 days)\n",
    "last_window = data_splits['X_test'][-1].flatten()\n",
    "future_predictions_df = predictor.predict_future(last_window, days=60)\n",
    "\n",
    "print(f\"Future predictions shape: {future_predictions_df.shape}\")\n",
    "print(\"\\nFirst 10 future predictions:\")\n",
    "print(future_predictions_df.head(10))\n",
    "\n",
    "# Classify future predictions\n",
    "classified_future_df = classifier.classify_future_predictions(future_predictions_df)\n",
    "\n",
    "print(\"\\nFuture classification distribution:\")\n",
    "print(classified_future_df['Classification'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc693454",
   "metadata": {},
   "source": [
    "## 12. Visualize Future Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bbaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot future predictions\n",
    "visualizer.plot_future_predictions(future_predictions_df)\n",
    "\n",
    "# Plot future predictions with risk classification\n",
    "visualizer.plot_future_with_classification(classified_future_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48558cc",
   "metadata": {},
   "source": [
    "## 13. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to CSV files\n",
    "output_dir = '../outputs'\n",
    "\n",
    "# Save classifications\n",
    "daily_classification.to_csv(f'{output_dir}/classifications/daily_classification_sample.csv', index=False)\n",
    "monthly_classification.to_csv(f'{output_dir}/classifications/monthly_classification_sample.csv', index=False)\n",
    "\n",
    "# Save future predictions\n",
    "future_predictions_df.to_csv(f'{output_dir}/predictions/future_predictions_sample.csv', index=False)\n",
    "\n",
    "# Save model\n",
    "model.save_model('../data/models/sample_stock_model.keras')\n",
    "\n",
    "print(\"All results saved successfully!\")\n",
    "print(f\"- Daily classifications: {output_dir}/classifications/daily_classification_sample.csv\")\n",
    "print(f\"- Monthly classifications: {output_dir}/classifications/monthly_classification_sample.csv\")\n",
    "print(f\"- Future predictions: {output_dir}/predictions/future_predictions_sample.csv\")\n",
    "print(f\"- Model: ../data/models/sample_stock_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0eeb7d",
   "metadata": {},
   "source": [
    "## 14. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07daacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Stock Price Prediction Analysis Summary ===\")\n",
    "print(f\"Stock analyzed: SAMPLE\")\n",
    "print(f\"Data period: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Total data points: {len(df)}\")\n",
    "print(f\"Window size: {processor.window_size} days\")\n",
    "print(f\"Model architecture: LSTM({model.lstm_units}) + Dense({model.dense_units})\")\n",
    "print(f\"Test MAE: {test_metrics['MAE']:.6f}\")\n",
    "print(f\"Test RMSE: {test_metrics['RMSE']:.6f}\")\n",
    "print(f\"Future predictions: {len(future_predictions_df)} days\")\n",
    "\n",
    "print(\"\\n=== Risk Classification Summary ===\")\n",
    "daily_dist = daily_classification['Classification'].value_counts()\n",
    "for cls, count in daily_dist.items():\n",
    "    percentage = (count / len(daily_classification)) * 100\n",
    "    print(f\"{cls}: {count} days ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== Next Steps ===\")\n",
    "print(\"1. Try with your own stock data by updating the data_path variable\")\n",
    "print(\"2. Experiment with different model parameters (LSTM units, window size, etc.)\")\n",
    "print(\"3. Use the main.py script for automated analysis\")\n",
    "print(\"4. Explore batch processing for multiple stocks\")\n",
    "print(\"5. Fine-tune classification thresholds based on your risk preferences\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
